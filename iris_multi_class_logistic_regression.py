# -*- coding: utf-8 -*-
"""iris multi class logistic regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17T7l-7TbJvhbfGaxxKERJN2lBQ9WWHd0
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df=pd.read_csv("/content/Iris.csv")

df.head()

df.shape

df.describe()

"""UNIVARIATE ANALYSIS OF INPUT FEATURES

UNIVARIATE ANALYSIS OF SepalLengthCm
"""

df['SepalLengthCm'].plot(kind='box')

df['SepalLengthCm'].plot(kind='kde')

df['SepalLengthCm'].skew()

"""UNIVARIATE ANALYSIS OF SepalWidthCm"""

df['SepalWidthCm'].plot(kind='box')
# these outliers are biological variations and hence, are to be taken into consideration for model building

df['SepalWidthCm'].plot(kind='kde')

df['SepalWidthCm'].skew()

"""UNIVARIATE ANALYSIS OF PetalLengthCm"""

df['PetalLengthCm'].plot(kind='box')

df['PetalLengthCm'].plot(kind='kde')

df['PetalLengthCm'].skew()

"""UNIVARIATE ANALYSIS OF PetalWidthCm

"""

df['PetalWidthCm'].plot(kind='box')

df['PetalWidthCm'].plot(kind='kde')

df['PetalWidthCm'].skew()

"""X AND Y

"""

X = df.drop(columns=['Id','Species'])

X

Y = df['Species']

Y

"""MODEL BUILDING"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

scaler=StandardScaler()
X_scaled=scaler.fit_transform(X)

le = LabelEncoder()
Y_label = le.fit_transform(Y)

import torch
import torch.nn as nn
import torch.optim as optim

X_tensor = torch.tensor(X_scaled,dtype=torch.float32)
Y_tensor = torch.tensor(Y_label,dtype=torch.long)

X_train_tensor,X_test_tensor,Y_train_tensor,Y_test_tensor=train_test_split(X_tensor,Y_tensor,test_size=0.2,random_state=42)

class SoftMaxRegression(nn.Module):
  def __init__(self,in_features,out_features):
    super().__init__()
    self.layer = nn.Linear(in_features,out_features)
  def forward(self,X_train_tensor):
    return self.layer(X_train_tensor)

model=SoftMaxRegression(in_features=4, out_features=3) # as the number of classes=3
print(model)

learning_rate=0.01
optimizer=optim.Adam(model.parameters(),lr=learning_rate)
criterion=nn.CrossEntropyLoss()

epochs=500
for epoch in range(epochs):
  y_hat = model(X_train_tensor)
  loss=criterion(y_hat,Y_train_tensor)
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
  if (epoch%100==0):
    print(f"epoch {epoch}, loss {loss}")
print(f"epoch 500, loss {loss}")

model.eval()
with torch.no_grad():
  output=model(X_test_tensor)
  _, prediction = torch.max(output,1)
  correct_prediction = (prediction==Y_test_tensor).sum().item()
  total = Y_test_tensor.size(0)
  accuracy = correct_prediction/total
  loss=criterion(output,Y_test_tensor)
  print(f"The loss on test data is {loss}")
  print(f"The accuracy on the test data is {accuracy}")

from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix

cm = confusion_matrix(Y_test_tensor.numpy(), prediction.numpy())
display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Setosa','Versicolor','Virginica'])
display.plot(cmap=plt.cm.Blues)
plt.title('Iris Species Confusion Matrix')
plt.show()